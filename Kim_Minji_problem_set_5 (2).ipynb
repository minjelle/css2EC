{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Kim_Minji_problem_set_5.ipynb","provenance":[],"authorship_tag":"ABX9TyPtiuORXbBMnNJ7XuHFTqyp"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"WmhdThsVGbSA"},"source":["### **Block 1**"]},{"cell_type":"code","metadata":{"id":"kKlfs9DyFdp0","executionInfo":{"status":"ok","timestamp":1621207299068,"user_tz":420,"elapsed":1061,"user":{"displayName":"Minji Kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOVxollZo-Y0MackC7kKgL6xZLxes12AQiNucr=s64","userId":"09451735684725887151"}}},"source":["#importing the relevant libraries\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XhgpJQVFGw6u"},"source":["## **Block 2**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dAcE4wds62sX","executionInfo":{"status":"ok","timestamp":1620023871632,"user_tz":420,"elapsed":750,"user":{"displayName":"Minji Kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOVxollZo-Y0MackC7kKgL6xZLxes12AQiNucr=s64","userId":"09451735684725887151"}},"outputId":"e1941a55-56f9-438f-c0ec-5fc363fb6bc1"},"source":["#2a. load the data\n","print('------------ 2a ------------')\n","data = pd.read_excel('messed_up_iris.xlsx',index_col=0)\n","print('data has been loaded')\n","print('\\n')\n","\n","#2b. check for no extra index columns using data.head()\n","print('------------ 2b ------------')\n","print(data.head())\n","print('\\n')\n","\n","#2c. Show the shape of the data\n","print('------------ 2c ------------')\n","data.shape\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["------------ 2a ------------\n","data has been loaded\n","\n","\n","------------ 2b ------------\n","   sepal_length  sepal_width  petal_length  petal_width species   color  origin\n","0           5.1          3.5           1.4          0.2  setosa   green     usa\n","1           4.9          3.0           1.4          0.2  setosa  yellow     usa\n","2           4.7          3.2           1.3          0.2  setosa   green     usa\n","3           4.6          3.1           1.5          0.2  setosa  orange   japan\n","4           5.0          3.6           1.4          0.2  setosa    blue  europe\n","\n","\n","------------ 2c ------------\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["(150, 7)"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"markdown","metadata":{"id":"bo28t1smKNc2"},"source":["## **Block 3**"]},{"cell_type":"code","metadata":{"id":"1804HIj5KjDK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620023871813,"user_tz":420,"elapsed":922,"user":{"displayName":"Minji Kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOVxollZo-Y0MackC7kKgL6xZLxes12AQiNucr=s64","userId":"09451735684725887151"}},"outputId":"8c395241-d2be-4072-f470-b21c4d7e417b"},"source":["#3a. Remove columns and rows where there are more than 50% of the data missing\n","print('------------ 3a ------------')\n","no_colors = data.drop(['color'], axis=1)\n","print(no_colors)\n","print('\\n')\n","\n","data2 = no_colors.dropna(thresh = (len(data.columns) * 0.5))\n","data3 = data2.dropna(thresh = (len(data2.index) * 0.5),axis=1)\n","print('columns/rows with more than 50% missing data have been removed')\n","print('\\n')\n","print(data3)\n","print('\\n')\n","\n","#3b. Show the shape of the data after you have removed those columns/rows\n","print('------------ 3b ------------')\n","print(data3.shape)\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["------------ 3a ------------\n","     sepal_length  sepal_width  petal_length  petal_width    species  origin\n","0             5.1          3.5           1.4          0.2     setosa     usa\n","1             4.9          3.0           1.4          0.2     setosa     usa\n","2             4.7          3.2           1.3          0.2     setosa     usa\n","3             4.6          3.1           1.5          0.2     setosa   japan\n","4             5.0          3.6           1.4          0.2     setosa  europe\n","..            ...          ...           ...          ...        ...     ...\n","145           6.7          3.0           5.2          2.3  virginica  europe\n","146           6.3          2.5           5.0          1.9  virginica   japan\n","147           6.5          3.0           5.2          2.0  virginica   japan\n","148           NaN          3.4           5.4          2.3  virginica   japan\n","149           5.9          3.0           5.1          1.8  virginica     usa\n","\n","[150 rows x 6 columns]\n","\n","\n","columns/rows with more than 50% missing data have been removed\n","\n","\n","     sepal_length  sepal_width  petal_length  petal_width    species  origin\n","0             5.1          3.5           1.4          0.2     setosa     usa\n","1             4.9          3.0           1.4          0.2     setosa     usa\n","2             4.7          3.2           1.3          0.2     setosa     usa\n","3             4.6          3.1           1.5          0.2     setosa   japan\n","4             5.0          3.6           1.4          0.2     setosa  europe\n","..            ...          ...           ...          ...        ...     ...\n","145           6.7          3.0           5.2          2.3  virginica  europe\n","146           6.3          2.5           5.0          1.9  virginica   japan\n","147           6.5          3.0           5.2          2.0  virginica   japan\n","148           NaN          3.4           5.4          2.3  virginica   japan\n","149           5.9          3.0           5.1          1.8  virginica     usa\n","\n","[145 rows x 6 columns]\n","\n","\n","------------ 3b ------------\n","(145, 6)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6iKBsM9knk5q"},"source":["## **Block 4**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JoljTbdUoE9A","executionInfo":{"status":"ok","timestamp":1620023871814,"user_tz":420,"elapsed":910,"user":{"displayName":"Minji Kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOVxollZo-Y0MackC7kKgL6xZLxes12AQiNucr=s64","userId":"09451735684725887151"}},"outputId":"33ee14de-5966-4511-cd25-5d1df1245581"},"source":["#4a. Remove duplicate data, if there is any. \n","print('------------ 4a ------------')\n","print(data3.duplicated())\n","print(\"\\n\")\n","\n","print('Are there any dupes?')\n","print(any(data3.duplicated()))\n","print(\"\\n\")\n","\n","print(data3[data.duplicated(keep=False)])\n","print(\"\\n\")\n","\n","data_nodupes = data3.drop_duplicates(ignore_index=True)\n","\n","print('Are there any dupes?')\n","print(any(data_nodupes.duplicated()))\n","print(\"\\n\")\n","\n","#4b. Show the shape of the data\n","print('------------ 4b ------------')\n","print(data_nodupes.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["------------ 4a ------------\n","0      False\n","1      False\n","2      False\n","3      False\n","4      False\n","       ...  \n","145    False\n","146    False\n","147    False\n","148    False\n","149    False\n","Length: 145, dtype: bool\n","\n","\n","Are there any dupes?\n","True\n","\n","\n","    sepal_length  sepal_width  petal_length  petal_width species  origin\n","21           5.1          3.7           1.5          0.4  setosa  europe\n","34           5.1          3.7           1.5          0.4  setosa  europe\n","37           4.9          3.6           1.4          0.1  setosa   japan\n","42           5.1          3.7           1.5          0.4  setosa  europe\n","59           4.9          3.6           1.4          0.1  setosa   japan\n","87           4.9          3.6           1.4          0.1  setosa   japan\n","\n","\n","Are there any dupes?\n","False\n","\n","\n","------------ 4b ------------\n","(140, 6)\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n","  # Remove the CWD from sys.path while we load stuff.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"WTgm_TOrnq98"},"source":["## **Block 5**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HTe-NAJroEYX","executionInfo":{"status":"ok","timestamp":1620023871816,"user_tz":420,"elapsed":902,"user":{"displayName":"Minji Kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOVxollZo-Y0MackC7kKgL6xZLxes12AQiNucr=s64","userId":"09451735684725887151"}},"outputId":"58769f7f-32e9-4d55-ca3a-f858aa793fe6"},"source":["#5a. Dummy code the categorical data. \n","print('------------ 5a ------------')\n","#start by correcting the mispellings\n","data_nodupes['species'] = np.where(data_nodupes['species']=='versicolr','versicolor',data_nodupes['species'])\n","data_nodupes['species'] = np.where(data_nodupes['species']=='virginia','virginica',data_nodupes['species'])\n","data_nodupes['species'] = np.where(data_nodupes['species']=='west virginia','virginica',data_nodupes['species'])\n","data_nodupes['species'] = np.where(data_nodupes['species']=='seotsa','setosa',data_nodupes['species'])\n","data_nodupes['origin'] = np.where(data_nodupes['origin']=='euarope','europe',data_nodupes['origin'])\n","data_nodupes['origin'] = np.where(data_nodupes['origin']=='uas','usa',data_nodupes['origin'])\n","\n","\n","print(\"species_df:\")\n","species_df = pd.get_dummies(data_nodupes['species'],drop_first=1)\n","print(species_df)\n","print(\"\\n\")\n","\n","print(\"origin_df:\")\n","origin_df = pd.get_dummies(data_nodupes['origin'],drop_first=1)\n","print(origin_df)\n","print(\"\\n\")\n","\n","#5b. Show the head of the data\n","print('------------ 5b ------------')\n","print(species_df.head())\n","print(\"\\n\")\n","print(origin_df.head())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["------------ 5a ------------\n","species_df:\n","     versicolor  virginica\n","0             0          0\n","1             0          0\n","2             0          0\n","3             0          0\n","4             0          0\n","..          ...        ...\n","135           0          1\n","136           0          1\n","137           0          1\n","138           0          1\n","139           0          1\n","\n","[140 rows x 2 columns]\n","\n","\n","origin_df:\n","     japan  usa\n","0        0    1\n","1        0    1\n","2        0    1\n","3        1    0\n","4        0    0\n","..     ...  ...\n","135      0    0\n","136      1    0\n","137      1    0\n","138      1    0\n","139      0    1\n","\n","[140 rows x 2 columns]\n","\n","\n","------------ 5b ------------\n","   versicolor  virginica\n","0           0          0\n","1           0          0\n","2           0          0\n","3           0          0\n","4           0          0\n","\n","\n","   japan  usa\n","0      0    1\n","1      0    1\n","2      0    1\n","3      1    0\n","4      0    0\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  after removing the cwd from sys.path.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \"\"\"\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  import sys\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  if __name__ == '__main__':\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"1eN2wtNlnvvm"},"source":["## **Block 6**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":289},"id":"ptG-T6S9oQAZ","executionInfo":{"status":"ok","timestamp":1620023871945,"user_tz":420,"elapsed":1022,"user":{"displayName":"Minji Kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOVxollZo-Y0MackC7kKgL6xZLxes12AQiNucr=s64","userId":"09451735684725887151"}},"outputId":"f3f3de95-ad77-470a-ec30-b848a4435abe"},"source":["#6a. Drop the redundant columns from the dataframe so that you are left with just the dummy coded columns. \n","print('------------ 6a ------------')\n","print('redundant columns have been dropped')\n","data_nodupes = pd.concat([data_nodupes.drop('species', axis=1), species_df], axis=1)\n","data_nodupes = pd.concat([data_nodupes.drop('origin', axis=1), origin_df], axis=1)\n","print('\\n')\n","\n","#6b. Show the head of the data\n","print('------------ 6b ------------')\n","data_nodupes.head()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["------------ 6a ------------\n","redundant columns have been dropped\n","\n","\n","------------ 6b ------------\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sepal_length</th>\n","      <th>sepal_width</th>\n","      <th>petal_length</th>\n","      <th>petal_width</th>\n","      <th>versicolor</th>\n","      <th>virginica</th>\n","      <th>japan</th>\n","      <th>usa</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5.1</td>\n","      <td>3.5</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>4.9</td>\n","      <td>3.0</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>4.7</td>\n","      <td>3.2</td>\n","      <td>1.3</td>\n","      <td>0.2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4.6</td>\n","      <td>3.1</td>\n","      <td>1.5</td>\n","      <td>0.2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5.0</td>\n","      <td>3.6</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   sepal_length  sepal_width  petal_length  ...  virginica  japan  usa\n","0           5.1          3.5           1.4  ...          0      0    1\n","1           4.9          3.0           1.4  ...          0      0    1\n","2           4.7          3.2           1.3  ...          0      0    1\n","3           4.6          3.1           1.5  ...          0      1    0\n","4           5.0          3.6           1.4  ...          0      0    0\n","\n","[5 rows x 8 columns]"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"o22zt0RTnxNc"},"source":["## **Block 7**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ia2rjVmFoUTp","executionInfo":{"status":"ok","timestamp":1620023871948,"user_tz":420,"elapsed":1015,"user":{"displayName":"Minji Kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOVxollZo-Y0MackC7kKgL6xZLxes12AQiNucr=s64","userId":"09451735684725887151"}},"outputId":"9164579f-da17-406a-e2d8-5c0622ca77fc"},"source":["#7a. Remove outliers above 2 standard deviations.\n","print('------------ 7a ------------')\n","print('outliers removed')\n","def remove_outliers(ser):\n","\n","  Q1 = ser.quantile(.25)\n","  Q3 = ser.quantile(.75)\n","  IQR = Q3-Q1\n","\n","  return np.where((ser > (Q3+(IQR*1.5))) | (ser < (Q1-(IQR*1.5))),np.nan,ser)\n","\n","for column in data_nodupes.columns:\n","  if isinstance(data_nodupes[column][0],float)==1:\n","    data_nodupes[column] = remove_outliers(data_nodupes[column])\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["------------ 7a ------------\n","outliers removed\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ToLGZGdInzjP"},"source":["## **Block 8**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":221},"id":"NN1JcREzoZU7","executionInfo":{"status":"ok","timestamp":1620023872106,"user_tz":420,"elapsed":1126,"user":{"displayName":"Minji Kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOVxollZo-Y0MackC7kKgL6xZLxes12AQiNucr=s64","userId":"09451735684725887151"}},"outputId":"196c7eb4-4de9-4dda-f2dc-8fab63008901"},"source":["#8a. For the remaining missing data, replace with the median value.\n","print('------------ 8a ------------')\n","data4 = data_nodupes.fillna(data.median())\n","final_data = pd.concat([data4], axis=1)\n","final_data.head()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["------------ 8a ------------\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sepal_length</th>\n","      <th>sepal_width</th>\n","      <th>petal_length</th>\n","      <th>petal_width</th>\n","      <th>versicolor</th>\n","      <th>virginica</th>\n","      <th>japan</th>\n","      <th>usa</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5.1</td>\n","      <td>3.5</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>4.9</td>\n","      <td>3.0</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>4.7</td>\n","      <td>3.2</td>\n","      <td>1.3</td>\n","      <td>0.2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4.6</td>\n","      <td>3.1</td>\n","      <td>1.5</td>\n","      <td>0.2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5.0</td>\n","      <td>3.6</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   sepal_length  sepal_width  petal_length  ...  virginica  japan  usa\n","0           5.1          3.5           1.4  ...          0      0    1\n","1           4.9          3.0           1.4  ...          0      0    1\n","2           4.7          3.2           1.3  ...          0      0    1\n","3           4.6          3.1           1.5  ...          0      1    0\n","4           5.0          3.6           1.4  ...          0      0    0\n","\n","[5 rows x 8 columns]"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"eM-w3_UvrEs5"},"source":["## **Block 9 - EC**"]},{"cell_type":"markdown","metadata":{"id":"AnxDBNDAn4OY"},"source":["## **Block 10**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"64at_luHodSr","executionInfo":{"status":"ok","timestamp":1620023872108,"user_tz":420,"elapsed":1121,"user":{"displayName":"Minji Kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOVxollZo-Y0MackC7kKgL6xZLxes12AQiNucr=s64","userId":"09451735684725887151"}},"outputId":"31bdd454-3b99-4e47-f607-6ca9ef856c9c"},"source":["#10a. Show (i.e., print) that there are no missing data\n","print('------------ 10a ------------')\n","print(final_data.info())\n","print('\\n')\n","\n","#10b. use the describe method to show off the final dataset\n","print('------------ 10b ------------')\n","print(final_data.describe())\n","#print(final_data.shape)\n","#print(final_data)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["------------ 10a ------------\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 140 entries, 0 to 139\n","Data columns (total 8 columns):\n"," #   Column        Non-Null Count  Dtype  \n","---  ------        --------------  -----  \n"," 0   sepal_length  140 non-null    float64\n"," 1   sepal_width   140 non-null    float64\n"," 2   petal_length  140 non-null    float64\n"," 3   petal_width   140 non-null    float64\n"," 4   versicolor    140 non-null    uint8  \n"," 5   virginica     140 non-null    uint8  \n"," 6   japan         140 non-null    uint8  \n"," 7   usa           140 non-null    uint8  \n","dtypes: float64(4), uint8(4)\n","memory usage: 5.0 KB\n","None\n","\n","\n","------------ 10b ------------\n","       sepal_length  sepal_width  ...       japan         usa\n","count    140.000000   140.000000  ...  140.000000  140.000000\n","mean       5.872143     3.047857  ...    0.300000    0.364286\n","std        0.791508     0.416126  ...    0.459903    0.482957\n","min        4.300000     2.000000  ...    0.000000    0.000000\n","25%        5.200000     2.800000  ...    0.000000    0.000000\n","50%        5.800000     3.000000  ...    0.000000    0.000000\n","75%        6.400000     3.300000  ...    1.000000    1.000000\n","max        7.900000     4.200000  ...    1.000000    1.000000\n","\n","[8 rows x 8 columns]\n"],"name":"stdout"}]}]}